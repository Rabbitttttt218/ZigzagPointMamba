<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding - Diao et al.">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="Novel state-space model for point cloud analysis using zigzag scan paths and Semantic-Siamese Masking Strategy, achieving superior performance on classification and segmentation tasks.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="Point cloud understanding, State-space models, Mamba, self-supervised learning, Masked Autoencoder">
  <!-- TODO: List all authors -->
  <meta name="author" content="Linshuang Diao, Sensen Song, Yurong Qian, Dayong Ren">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Xinjiang University & Nanjing University">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding">

  <!-- TODO: Same as description above -->
  <meta property="og:description" content="Novel state-space model for point cloud analysis using zigzag scan paths and Semantic-Siamese Masking Strategy, achieving superior performance on classification and segmentation tasks.">

  <!-- TODO: Replace with your actual website URL -->
  <!-- 换成自己的链接 -->
  <!-- 链接修改 -->
  <meta property="og:url" content="https://Rabbitttttt218.github.io/ZigzagPointMamba">

  <!-- TODO: Create a 1200x630px preview image and update path -->
  <!-- 搞清楚哪些图放在哪里合适 -->
  <!-- 链接修改 -->
  <meta property="og:image:alt" content="https://Rabbitttttt218.github.io/ZigzagPointMamba/static/images/pipeline.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">

  <meta property="og:image:alt" content="PAPER_TITLE-Research Preview">
  <meta property="article:published_time" content="2025">
  <meta property="article:author" content="Linshuang Diao">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Point cloud">
  <meta property="article:tag" content="Mamba">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <!-- <meta name="twitter:site" content="@XinjiangUniv">-->

  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@LinshuangDiao">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="Novel state-space model for point cloud analysis using zigzag scan paths and Semantic-Siamese Masking Strategy, achieving superior performance on classification and segmentation tasks.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://Rabbitttttt218.github.io/ZigzagPointMamba/static/images/pipeline.png">
  <meta name="twitter:image:alt" content="ZigzagPointMamba-Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding">
  <meta name="citation_author" content="Diao, Linshuang">
  <meta name="citation_author" content="Song, Sensen">
  <meta name="citation_author" content="Qian, Yurong">
  <meta name="citation_author" content="Ren, Dayong">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="The Thirty-ninth Annual Conference on Neural Information Processing Systems">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2505.21381.pdf">

  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding | NeurIPS 2025</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding",
    "description": "Novel state-space model for point cloud analysis using zigzag scan paths and Semantic-Siamese Masking Strategy, achieving superior performance on classification and segmentation tasks.",
    "author": [
      {
        "@type": "Person",
        "name": "Linshuang Diao",
        "affiliation": {
          "@type": "Organization",
          "name": "Xinjiang University"
        }
      },
      {
        "@type": "Person",
        "name": "Sensen Song",
        "affiliation": {
          "@type": "Organization",
          "name": "Xinjiang University"
        }
      },
      {
        "@type": "Person",
        "name": "Yurong Qian",
        "affiliation": {
          "@type": "Organization",
          "name": "Xinjiang University"
        }
      }
      {
        "@type": "Person",
        "name": "Dayong Ren",
        "affiliation": {
          "@type": "Organization",
          "name": "Nanjing University"
        }
      }
    ],
    "datePublished": "2025",
    "publisher": {
      "@type": "Organization",
      "name": "The Thirty-ninth Annual Conference on Neural Information Processing Systems"
    },
    "url": "https://Rabbitttttt218.github.io/ZigzagPointMamba",
    "image": "https://Rabbitttttt218.github.io/ZigzagPointMamba/static/images/pipeline.png",
    "keywords": ["Point cloud understanding", "State-space models", "Mamba", "self-supervised learning", "Masked Autoencoder"],
    "abstract": "State Space models (SSMs) like PointMamba provide efficient feature extraction for point cloud self-supervised learning with linear complexity, surpassing Transformers in computational efficiency. However, existing PointMamba-based methods rely on complex token ordering and random masking, disrupting spatial continuity and local semantic correlations. We propose <strong>ZigzagPointMamba</strong> to address these challenges. The key to our approach is a simple zigzag scan path that globally sequences point cloud tokens, enhancing spatial continuity by preserving the proximity of spatially adjacent point tokens. Yet, random masking impairs local semantic modeling in self-supervised learning. To overcome this, we introduce a Semantic-Siamese Masking Strategy (SMS), which masks semantically similar tokens to facilitate reconstruction by integrating local features of original and similar tokens, thus overcoming dependence on isolated local features and enabling robust global semantic modeling. Our pre-training ZigzagPointMamba weights significantly boost downstream tasks, achieving a 1.59% mIoU gain on ShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for classification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for the classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of ScanObjectNN.",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://Rabbitttttt218.github.io/ZigzagPointMamba"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Point cloud understanding"
      },
      {
        "@type": "Thing", 
        "name": "State-space models"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Xinjiang University",
    "url": "https://www.xju.edu.cn",
    "sameAs": [
      "https://github.com/Rabbitttttt218"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="mailto:107552304043@stu.xju.edu.cn">Linshuang Diao</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="mailto:songsensen@stu.xju.edu.cn">Sensen Song</a><sup>1†</sup>,</span>
              <span class="author-block">
                <a href="mailto:qyr@stu.xju.edu.cn">Yurong Qian</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="mailto:rdyedu@gmail.com">Dayong Ren</a><sup>3†</sup>
              </span>
              </div>

                  <!-- <div class="is-size-5 publication-authors"> -->
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <!-- <span class="author-block"><sup>1</sup>Xinjiang University &nbsp;&nbsp; <sup>2</sup>Nanjing University<br>NeurIPS 2025</span> -->
                  <!-- </div> -->
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Key Laboratory of Signal Detection and Processing, Xinjiang University &nbsp;&nbsp;
                      <sup>2</sup>Joint International Research Laboratory of Silk Road Multilingual Cognitive Computing, Xinjiang University &nbsp;&nbsp;
                      <sup>3</sup>Department of Computer Science and Technology, Nanjing University<br>
                      <sup>†</sup>Corresponding authors | NeurIPS 2025
                    </span>
                  </div>
                  
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org//abs/2505.21381" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/Rabbitttttt218/ZigzagPointMamba" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.21381" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            State Space models (SSMs) like PointMamba provide efficient feature extraction for point cloud self-supervised learning with linear complexity, surpassing Transformers in computational efficiency. However, existing PointMamba-based methods rely on complex token ordering and random masking, disrupting spatial continuity and local semantic correlations. We propose <strong>ZigzagPointMamba</strong> to address these challenges. The key to our approach is a simple zigzag scan path that globally sequences point cloud tokens, enhancing spatial continuity by preserving the proximity of spatially adjacent point tokens. Yet, random masking impairs local semantic modeling in self-supervised learning. To overcome this, we introduce a Semantic-Siamese Masking Strategy (SMS), which masks semantically similar tokens to facilitate reconstruction by integrating local features of original and similar tokens, thus overcoming dependence on isolated local features and enabling robust global semantic modeling. Our pre-training ZigzagPointMamba weights significantly boost downstream tasks, achieving a 1.59% mIoU gain on ShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for classification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for the classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of ScanObjectNN.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/comprehensive_results.png" alt="Comprehensive results showing performance comparison, masking strategy effects, and fine-tuning improvements" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          Comprehensive Results: (a) Performance comparison across datasets, (b) SMS vs. random masking reconstruction quality, (c) Feature representations before and after fine-tuning.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/pipeline.png" alt="ZigzagPointMamba pre-training pipeline with zigzag scan and SMS" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Pipeline Overview: ZigzagPointMamba pre-training with zigzag scan path and Semantic-Siamese Masking Strategy.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/zigzag_path_and_masking.png" alt="Zigzag scan path and semantic masking visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Zigzag Scan Path: 3D extension preserving spatial proximity while SMS masks semantically similar tokens.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/Classification_on_ModelNet40_and_Part_Seg_on_ShapeNetPart.png" alt="Experimental results on ModelNet40 and ShapeNet Part" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Experimental Results: Classification on ModelNet40 and part segmentation on ShapeNet Part datasets.
      </h2>
    </div>
    <div class="item">
      <img src="static/images/Few-shot.png" alt="Few-shot learning results on ModelNet40" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Few-shot Learning: Superior performance on ModelNet40 few-shot classification tasks.
      </h2>
    </div>
    <div class="item">
      <img src="static/images/ScanobjNN.png" alt="ScanObjectNN classification results" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        ScanObjectNN Results: Consistent improvements across OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdfs/NeurIPS2025_9291_ZiazagPointMamba.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{diao2025zigzagpointmamba,
  title={ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding},
  author={Diao, Linshuang and Song, Sensen and Qian, Yurong and Ren, Dayong},
  booktitle={Advances in neural information processing systems},
  year={2025}
}</code></pre>
    </div>
</section>


    
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Additional Qualitative Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Additional Qualitative Results</h2>
      <div class="columns is-multiline">
        <div class="column is-12">
          <div class="content">
            <h3 class="subtitle is-4">Reconstruction Quality Analysis</h3>
            <figure class="image">
              <img src="static/images/reconstruction_results.png" alt="Qualitative analysis of mask predictions on ShapeNet validation set" loading="lazy"/>
              <figcaption class="has-text-centered is-size-6 has-text-grey">
                <strong>Figure:</strong> Qualitative analysis of mask predictions from ZigzagPointMamba on ShapeNet validation set. From left to right: Input point cloud, Masked version, Reconstructed result, and additional object examples.
              </figcaption>
            </figure>
          </div>
        </div>
        
        <div class="column is-12">
          <div class="content">
            <h3 class="subtitle is-4">Part Segmentation Comparison</h3>
            <figure class="image">
              <img src="static/images/segmentation_comparison.png" alt="Comparison of part segmentation results between PointMamba and ZigzagPointMamba" loading="lazy"/>
              <figcaption class="has-text-centered is-size-6 has-text-grey">
                <strong>Figure:</strong> Qualitative comparison of part segmentation results. Top: Ground Truth, Middle: PointMamba predictions, Bottom: ZigzagPointMamba predictions. Objects include laptop, lamp, guitar, airplane, and table.
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Additional Qualitative Results -->
<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
